import modal
from modal import Image, App, asgi_app, Secret
from typing import List, Optional
import time

MODEL_DIR = "/model"
MODEL_NAME = "openai/whisper-large-v3"
MODEL_REVISION = "afda370583db9c5359511ed5d989400a6199dfe1"

# Modal iÃ§in container image'Ä± tanÄ±mla - gÃ¼ncel kÃ¼tÃ¼phane sÃ¼rÃ¼mleriyle
image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "torch==2.5.1",
        "transformers==4.47.1",
        "hf-transfer==0.1.8",
        "huggingface_hub==0.27.0",
        "librosa==0.10.2",
        "soundfile==0.12.1",
        "accelerate==1.2.1",
        "datasets==3.2.0",
        "fastapi",
        "python-multipart",
        "uvicorn",
        "numpy",
    )
    # HÄ±zlÄ± indirme iÃ§in hf-transfer kullan
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1", "HF_HUB_CACHE": MODEL_DIR})
)

# Model cache iÃ§in Volume
model_cache = modal.Volume.from_name("hf-hub-cache", create_if_missing=True)

# Modal App'i oluÅŸtur
app = modal.App(
    "callmetric-ai-api-batched",
    image=image,
    volumes={MODEL_DIR: model_cache},
    secrets=[Secret.from_name("openai-secret")], # Gerekirse diÄŸer secret'larÄ± ekleyin
)

# Model aÄŸÄ±rlÄ±klarÄ±nÄ± Ã¶nden indir
@app.function()
def download_model():
    """Model aÄŸÄ±rlÄ±klarÄ±nÄ± indirir ve cache'e kaydeder."""
    from huggingface_hub import snapshot_download
    from transformers.utils import move_cache

    print("ğŸ“¥ Model indiriliyor...")
    snapshot_download(
        MODEL_NAME,
        ignore_patterns=["*.pt", "*.bin"],  # Sadece safetensors kullan
        revision=MODEL_REVISION,
    )
    move_cache()
    print("âœ… Model baÅŸarÄ±yla indirildi!")

# Modeli GPU Ã¼zerinde Ã§alÄ±ÅŸacak ÅŸekilde tanÄ±mla - Dynamic batching ile
@app.cls(
    gpu="a10g",  # A10G GPU kullan (daha iyi performans iÃ§in A100 veya H100 da kullanÄ±labilir)
    volumes={MODEL_DIR: model_cache},
    scaledown_window=300, # 5 dakika sonra container'Ä± kapat (eski adÄ±: container_idle_timeout)
    max_containers=10,  # Maksimum container sayÄ±sÄ±
)
class WhisperModel:
    @modal.enter()
    def load_model(self):
        """
        Container baÅŸladÄ±ÄŸÄ±nda modeli bir kereliÄŸine GPU'ya yÃ¼kler.
        """
        import torch
        from transformers import (
            AutoModelForSpeechSeq2Seq,
            AutoProcessor,
            pipeline,
        )

        print("ğŸš€ Model yÃ¼kleniyor...")

        # Model ve iÅŸlemciyi yÃ¼kle
        self.processor = AutoProcessor.from_pretrained(MODEL_NAME)
        model = AutoModelForSpeechSeq2Seq.from_pretrained(
            MODEL_NAME,
            torch_dtype=torch.float16,
            low_cpu_mem_usage=True,
            use_safetensors=True,
        ).to("cuda")

        # Default dil ayarÄ± (TÃ¼rkÃ§e)
        model.generation_config.language = "<|tr|>"

        # Transkripsiyon iÃ§in pipeline oluÅŸtur
        self.pipeline = pipeline(
            "automatic-speech-recognition",
            model=model,
            tokenizer=self.processor.tokenizer,
            feature_extractor=self.processor.feature_extractor,
            torch_dtype=torch.float16,
            device="cuda",
        )
        print("âœ… Model baÅŸarÄ±yla yÃ¼klendi!")

    def transcribe_single(self, audio_bytes: bytes, language: str = "tr") -> dict:
        """
        Tek bir ses dosyasÄ±nÄ± iÅŸler (batching olmadan direkt iÅŸler).
        """
        import librosa
        import io
        
        print(f"ğŸ¤ Tek ses dosyasÄ± iÅŸleniyor ({len(audio_bytes) / 1024:.2f} KB)...")
        
        # Ses dosyasÄ±nÄ± numpy array'e Ã§evir
        audio_array, _ = librosa.load(io.BytesIO(audio_bytes), sr=16000)
        
        # Transkripsiyon yap (dil ayarÄ±nÄ± generate_kwargs ile yapÄ±yoruz)
        result = self.pipeline(
            audio_array,
            chunk_length_s=30,
            return_timestamps=True,
            generate_kwargs={"language": language},
        )
        
        print(f"âœ… Transkripsiyon tamamlandÄ±!")
        return result

    # FastAPI uygulamasÄ±nÄ± WhisperModel class iÃ§inde tanÄ±mla
    @asgi_app()
    def fastapi_app(self):
        from fastapi import FastAPI, UploadFile, File, Form, HTTPException
        from fastapi.responses import JSONResponse
        from fastapi.middleware.cors import CORSMiddleware
        from typing import List

        web_app = FastAPI(
            title="CallMetric AI Whisper API",
            description="High-performance speech-to-text API with dynamic batching",
            version="2.0.0"
        )
        
        # CORS middleware ekle
        web_app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )

        @web_app.post("/transcribe")
        async def transcribe(
            audio_file: UploadFile = File(...),
            language: str = Form("tr"), # Dil parametresi, default 'tr'
        ):
            """
            Tek bir ses dosyasÄ±nÄ± yÃ¼kleyip transkriptini dÃ¶ndÃ¼ren API endpoint'i.
            Dynamic batching sayesinde otomatik olarak batch'lenir.
            """
            if not audio_file:
                raise HTTPException(status_code=400, detail="Ses dosyasÄ± bulunamadÄ±.")
            
            start_time = time.time()
            
            try:
                audio_bytes = await audio_file.read()
                
                # self.transcribe_single metodunu kullan (artÄ±k self.pipeline eriÅŸilebilir)
                result = self.transcribe_single(audio_bytes, language)
                
                processing_time = time.time() - start_time
                print(f"â±ï¸ Toplam iÅŸlem sÃ¼resi: {processing_time:.2f} saniye")
                
                return JSONResponse(
                    content={
                        "text": result.get("text", ""),
                        "chunks": result.get("chunks", []),
                        "processing_time_seconds": processing_time,
                        "filename": audio_file.filename,
                        "language": language,
                    }
                )
            except Exception as e:
                import traceback
                traceback.print_exc()
                raise HTTPException(status_code=500, detail=str(e))

        @web_app.post("/transcribe/batch")
        async def transcribe_batch(
            audio_files: List[UploadFile] = File(...),
            language: str = Form("tr"), # TÃ¼m dosyalar iÃ§in default dil
        ):
            """
            Birden fazla ses dosyasÄ±nÄ± aynÄ± anda iÅŸleyen batch endpoint'i.
            Dynamic batching ile maksimum performans saÄŸlar.
            """
            if not audio_files:
                raise HTTPException(status_code=400, detail="En az bir ses dosyasÄ± gerekli.")
            
            start_time = time.time()
            
            try:
                # TÃ¼m dosyalarÄ± oku
                audio_bytes_list = []
                filenames = []
                for audio_file in audio_files:
                    audio_bytes = await audio_file.read()
                    audio_bytes_list.append(audio_bytes)
                    filenames.append(audio_file.filename)
                
                # Batch halinde iÅŸle (her dosyayÄ± sÄ±rayla iÅŸle)
                results = []
                for audio_bytes in audio_bytes_list:
                    result = self.transcribe_single(audio_bytes, language)
                    results.append(result)
                
                processing_time = time.time() - start_time
                print(f"â±ï¸ {len(audio_files)} dosya {processing_time:.2f} saniyede iÅŸlendi")
                
                # SonuÃ§larÄ± formatla
                formatted_results = []
                for i, result in enumerate(results):
                    formatted_results.append({
                        "filename": filenames[i],
                        "text": result.get("text", ""),
                        "chunks": result.get("chunks", []),
                        "language": language,
                    })
                
                return JSONResponse(
                    content={
                        "results": formatted_results,
                        "total_files": len(audio_files),
                        "total_processing_time_seconds": processing_time,
                        "avg_processing_time_per_file": processing_time / len(audio_files),
                    }
                )
            except Exception as e:
                import traceback
                traceback.print_exc()
                raise HTTPException(status_code=500, detail=str(e))

        @web_app.get("/health")
        async def health_check():
            """SaÄŸlÄ±k kontrolÃ¼ endpoint'i"""
            return {"status": "healthy", "model": MODEL_NAME, "gpu": "A10G"}

        @web_app.get("/")
        async def root():
            """API bilgileri"""
            return {
                "message": "CallMetric AI Whisper API",
                "endpoints": {
                    "/transcribe": "Tek ses dosyasÄ± iÃ§in transkripsiyon",
                    "/transcribe/batch": "Ã‡oklu ses dosyasÄ± iÃ§in batch transkripsiyon",
                    "/health": "SaÄŸlÄ±k kontrolÃ¼",
                },
                "features": [
                    "Dynamic batching ile yÃ¼ksek performans",
                    "Whisper Large V3 modeli",
                    "Ã‡oklu dil desteÄŸi",
                    "Timestamp desteÄŸi",
                ]
            }

        return web_app

# Test iÃ§in local entrypoint
@app.local_entrypoint()
def test_model():
    """Model indirme ve test iÅŸlemi iÃ§in local entrypoint."""
    print("ğŸš€ CallMetric AI Whisper API - Test")
    print("=" * 50)
    
    # Model indir
    print("\nğŸ“¥ Model indiriliyor...")
    download_model.remote()
    
    print("\nâœ… Model baÅŸarÄ±yla indirildi!")
    print("\nğŸ“Œ API'yi deploy etmek iÃ§in:")
    print("   modal deploy app.py")
    print("\nğŸ“Œ API'yi test etmek iÃ§in:")
    print("   modal serve app.py")
    print("\nğŸŒ Endpoint'ler:")
    print("   POST /transcribe - Tek dosya transkripsiyon")
    print("   POST /transcribe/batch - Ã‡oklu dosya batch transkripsiyon")
    print("   GET /health - SaÄŸlÄ±k kontrolÃ¼")
    print("   GET / - API bilgileri")
    print("\nğŸ’¡ Dynamic batching ile 2.8x'e kadar performans artÄ±ÅŸÄ±!")
